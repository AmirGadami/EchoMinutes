{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llms/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import torch\n",
    "from huggingface_hub import hf_hub_download\n",
    "from diffusers import FluxPipeline\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer, BitsAndBytesConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!pip install diffusers transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "hf_token = os.getenv('HF_TOKEN')\n",
    "login(hf_token,add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9974709749221802}]\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('sentiment-analysis', device=device)\n",
    "result = classifier('I am grateful foe everything I have')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'I-PER', 'score': 0.9993376, 'index': 3, 'word': 'Amir', 'start': 4, 'end': 8}, {'entity': 'I-PER', 'score': 0.99954885, 'index': 4, 'word': 'G', 'start': 9, 'end': 10}, {'entity': 'I-PER', 'score': 0.9680944, 'index': 5, 'word': '##had', 'start': 10, 'end': 13}, {'entity': 'I-PER', 'score': 0.99728763, 'index': 6, 'word': '##ami', 'start': 13, 'end': 16}]\n"
     ]
    }
   ],
   "source": [
    "ner = pipeline('ner',device=device)\n",
    "result = ner('Dr. Amir Ghadami is a famouse Businessman and Scientist')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-7B-Instruct\",trust_remote_code = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode('I will be a multi millionaire by the age of 40, Also I will become a PhD at university of Toronto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 686, 387, 264, 7299, 88944, 553, 279, 4231, 315, 220, 19, 15, 11, 7281, 358, 686, 3635, 264, 29561, 518, 12103, 315, 14632]\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will be a multi millionaire by the age of 40, Also I will become a PhD at university of Toronto\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', ' will', ' be', ' a', ' multi', ' millionaire', ' by', ' the', ' age', ' of', ' ', '4', '0', ',', ' Also', ' I', ' will', ' become', ' a', ' PhD', ' at', ' university', ' of', ' Toronto']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.batch_decode(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell a light-hearted joke for a room of Data Scientists\"}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[151644,\n",
       " 8948,\n",
       " 198,\n",
       " 2610,\n",
       " 525,\n",
       " 264,\n",
       " 10950,\n",
       " 17847,\n",
       " 151645,\n",
       " 198,\n",
       " 151644,\n",
       " 872,\n",
       " 198,\n",
       " 40451,\n",
       " 264,\n",
       " 3100,\n",
       " 69295,\n",
       " 21646,\n",
       " 369,\n",
       " 264,\n",
       " 3054,\n",
       " 315,\n",
       " 2885,\n",
       " 56016,\n",
       " 151645,\n",
       " 198]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.apply_chat_template(messages,tokenizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHI3 = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "GEMMA2 = \"google/gemma-2-2b-it\"\n",
    "QWEN2 = \"Qwen/Qwen2-7B-Instruct\" \n",
    "MIXTRAL = \"mistralai/Mixtral-8x7B-Instruct-v0.1\" \n",
    "LLAMA = \"meta-llama/Meta-Llama-3.1-8B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell a light-hearted joke for a room of Data Scientists\"}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(PHI3)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.apply_chat_template(messages,return_tensors='pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[32006,   887,   526,   263,  8444, 20255, 32007, 32010, 24948,   263,\n",
       "          3578, 29899, 23057,   287,  2958,   446,   363,   263,  5716,   310,\n",
       "          3630, 23753,  2879, 32007, 32000]], device='mps:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7568efbddf80493b89cc432d814cf502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(LLAMA, device_map=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer, BitsAndBytesConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_MODEL = \"whisper-1\"\n",
    "LLAMA = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_TOKEN = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()\n",
    "def downlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = open('/Users/amir/Desktop/GitHub/EchoMinutes/denver_extract.mp3','rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = openai.audio.transcriptions.create(model=AUDIO_MODEL,file=audio_file,response_format='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ No MP3 found on page.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_mp3_link(page_url):\n",
    "    response = requests.get(page_url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    audio_tags = soup.find_all(\"audio\")\n",
    "    for tag in audio_tags:\n",
    "        if tag.get(\"src\"):\n",
    "            return tag[\"src\"]\n",
    "\n",
    "    for link in soup.find_all(\"a\"):\n",
    "        if link.get(\"href\", \"\").endswith(\".mp3\"):\n",
    "            return link[\"href\"]\n",
    "\n",
    "    return None\n",
    "\n",
    "# Example\n",
    "page = \"https://www.bbc.co.uk/sounds\"\n",
    "audio_url = scrape_mp3_link(page)\n",
    "\n",
    "if audio_url:\n",
    "    audio_data = requests.get(audio_url)\n",
    "    with open(\"news_audio.mp3\", \"wb\") as f:\n",
    "        f.write(audio_data.content)\n",
    "    print(\"âœ… MP3 downloaded!\")\n",
    "else:\n",
    "    print(\"âŒ No MP3 found on page.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Downloaded: news_clip.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: yt-dlp: command not found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def download_audio_from_url(url, output_name=\"news_clip.mp3\"):\n",
    "    os.system(f'yt-dlp -x --audio-format mp3 -o \"{output_name}\" \"{url}\"')\n",
    "    print(f\"âœ… Downloaded: {output_name}\")\n",
    "\n",
    "# Example (NPR news)\n",
    "url = \"https://www.wsj.com/audio\"\n",
    "download_audio_from_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yt_dlp'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myt_dlp\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdownload_audio\u001b[39m(youtube_url, output_filename=\u001b[33m\"\u001b[39m\u001b[33mdownloaded_audio.mp3\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# Options for audio-only download in mp3 format\u001b[39;00m\n\u001b[32m      7\u001b[39m     ydl_opts = {\n\u001b[32m      8\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mformat\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mbestaudio/best\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      9\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mouttmpl\u001b[39m\u001b[33m'\u001b[39m: output_filename,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mquiet\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     16\u001b[39m     }\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'yt_dlp'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import yt_dlp\n",
    "\n",
    "def download_audio(youtube_url, output_filename=\"downloaded_audio.mp3\"):\n",
    "    # Options for audio-only download in mp3 format\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'outtmpl': output_filename,\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "            'preferredquality': '192',\n",
    "        }],\n",
    "        'quiet': False\n",
    "    }\n",
    "\n",
    "    print(f\"ðŸŽ§ Downloading audio from: {youtube_url}\")\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([youtube_url])\n",
    "    print(f\"âœ… Done! Audio saved to: {output_filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) < 2:\n",
    "        print(\"âŒ Please provide a YouTube URL.\\nUsage: python download_youtube_audio.py https://youtube.com/watch?v=...\")\n",
    "    else:\n",
    "        youtube_url = sys.argv[1]\n",
    "        download_audio(youtube_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yt_dlp'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myt_dlp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'yt_dlp'"
     ]
    }
   ],
   "source": [
    "import yt_dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
